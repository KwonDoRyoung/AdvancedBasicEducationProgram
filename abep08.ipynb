{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1월4일자 권혁민",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonDoRyoung/AdvancedBasicEducationProgram/blob/main/abep08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.activation function: sigmoid, relu, softmax"
      ],
      "metadata": {
        "id": "gCAJyE20cLQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "8EbYQw5I4JJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # neural network\n",
        "import torch.nn.functional as F \n",
        "# neural network 기능 중에 함수형태로 프로그래밍된 친구들\n",
        "\n",
        "class SingleLayerPerceptron(nn.Module): \n",
        "  # torch에서는 역전파를 제공합니다.\n",
        "  # 선언한 class 에 nn.Module 이라는 class 상속 시키면.\n",
        "  # 상속: 미리 누군가 정의해둔 청사진 > 청사진을 토대로 제가 활용하는 것\n",
        "  # 알아서 backpropagation 정의됩니다.\n",
        "  def __init__(self,):\n",
        "    super(SingleLayerPerceptron, self).__init__() # <- 상속 하겠다.\n",
        "    # super.__init__() # or super(SingleLayerPerceptron, self).__init__()\n",
        "    # 모델에 구조를 선언하는 부분\n",
        "    self.fc = nn.Linear(784, 10, bias=False) # mnist 1,28,28 -> 784 펼쳤고, 맞춰야될 정답이 0~9 -> 10개\n",
        "    # 10개를 하나의 출력으로 맞추는 것은 힘들기 때문에\n",
        "    # 10개의 출력에 대한 확률을 구하고 거기서 제일 높은 확률을 가지는 인덱스를 정답으로 예측한다.\n",
        "    # 제일 높은 확률을 만들기 위해서는 softmax를 활용하고\n",
        "    # 비용함수는 cross entropy 활용한다.\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    # 입력받는 부분을 정의하는 곳\n",
        "    # 출력 내는 곳\n",
        "    outputs = self.fc(inputs)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "N4Dm-soE4dSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.utils\n",
        "t = torchvision.transforms.Compose([torchvision.transforms.PILToTensor()])\n",
        "dataset = MNIST(root=\"/content/mnist\", download=True, transform=t)\n",
        "# data ->index 0: image, 1: target \n",
        "# [[<pil.image class, 상수_target>] -> tensor\n",
        "# [<pil.image class, 상수_target>]\n",
        "# [<pil.image class, 상수_target>]\n",
        "# [<pil.image class, 상수_target>]]\n",
        "batch_size = 32\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 비용함수를 만드는 이유는 최적화.\n",
        "# 최소화 \n",
        "\n",
        "model = SingleLayerPerceptron().to(\"cuda\") # gpu에서 할거면 model, data 모든게 Gpu에 할당되야됨\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "end_epoch =100\n",
        "for epoch in range(end_epoch):\n",
        "  mean_cost = 0\n",
        "  count = 0\n",
        "  for step, (batch_image, batch_target) in enumerate(data_loader):\n",
        "    batch_image = torch.flatten(batch_image, start_dim=1).float().to(\"cuda\")\n",
        "    batch_target = batch_target.to(\"cuda\")\n",
        "    predicts = model(batch_image)\n",
        "\n",
        "    cost = criterion(predicts, batch_target)\n",
        "\n",
        "    optimizer.zero_grad() # 이전에 계산한 미분값 지우는 것\n",
        "    cost.backward() # 현재 데이터에 대한 미분값 계산\n",
        "    optimizer.step() # 현재 데이터로 만든 미분값으로 최적화를 해라.\n",
        "    \n",
        "    mean_cost += cost.item()\n",
        "    count += 1\n",
        "  if epoch % 5 == 0:\n",
        "    print(f\"[Epoch]: {epoch}, Loss: {mean_cost/count}\")"
      ],
      "metadata": {
        "id": "5KXuzCc85At5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p1f7iu6C5Aqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PehYdOXZ5AoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yj-ER3O85Alz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AzM3NJw25AdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIVTcrM9bgNr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "relu = nn.ReLU()\n",
        "softmax = nn.Softmax()"
      ],
      "metadata": {
        "id": "oKgMy9bgcYwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 1. sigmoid, rleu 그래프 그리기'''\n",
        "x = np.linspace(-7, 7, 100)\n",
        "y = sigmoid(torch.Tensor([x]))[0,:]\n",
        "z = relu(torch.Tensor([x]))[0,:]\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(x, y, color='green')\n",
        "plt.title('sigmoid')\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(x, z, color='steelblue')\n",
        "plt.title('relu')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pwYYxJ9zClyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2. softmax 특징'''\n",
        "print(softmax(torch.Tensor([2,3,4])))\n",
        "print(softmax(torch.Tensor([2,3,4])).sum())"
      ],
      "metadata": {
        "id": "r2-w8a0IEYLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.perceptron torch구현"
      ],
      "metadata": {
        "id": "hZIW1_NCdGjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "xkgowcMjZOJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300"
      ],
      "metadata": {
        "id": "Ci7Vmn7tbp73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' AND_gate 문제'''\n",
        "input = torch.FloatTensor([[0,0],[0,1],\n",
        "                           [1,0],[1,1]])\n",
        "target = torch.LongTensor([0,0,0,1])"
      ],
      "metadata": {
        "id": "x1uZbP5vXjrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 1. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ],
      "metadata": {
        "id": "mBMlQM3WZLTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2. Perceptron 모델 설계하기 '''\n",
        "class Perceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.fc = nn.Linear(2,2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "I7GOAjoRdKTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 3. Optimizer, Objective Function 설정하기 '''\n",
        "model = Perceptron().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Q_tXItWjYRmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 4. 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, input, target, optimizer, log_interval):\n",
        "    model.train()\n",
        "    input = input.to(DEVICE)\n",
        "    target = target.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input)\n",
        "    loss = criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "ueBNqaSiZX-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 5. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, input, target):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input = input.to(DEVICE)\n",
        "        target = target.to(DEVICE)\n",
        "        output = model(input)\n",
        "        test_loss += criterion(output, target).item()\n",
        "        prediction = output.max(1, keepdim = True)[1]\n",
        "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "    test_accuracy = 100. * correct / 4\n",
        "    return test_loss, prediction, test_accuracy"
      ],
      "metadata": {
        "id": "BUhQ56pIZatJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 6. MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, input, target, optimizer, log_interval = 200)\n",
        "    test_loss, prediction, test_accuracy = evaluate(model, input, target)\n",
        "    if (epoch)%10 == 0:\n",
        "        print(\"\\n[EPOCH: {}], \\toutput: {}, \\ttarget: {}, \\tLoss: {}, \\tTest Accuracy: {:.2f} %\".format(\n",
        "            epoch, prediction.view(4).tolist(), target.tolist(), test_loss, test_accuracy))"
      ],
      "metadata": {
        "id": "ElXOuXlLZczS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.multi-layer perceptron torch 구현\n",
        "MNIST"
      ],
      "metadata": {
        "id": "uMQH1ex9eQw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1Y1S7_P-fSaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "mvyJ0m-Ve-BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 1. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ],
      "metadata": {
        "id": "OASkrvAWi3m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Colab Notebooks/MNIST/mnist_train.csv'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/MNIST/mnist_test.csv'"
      ],
      "metadata": {
        "id": "-6CQv71Or7LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset1(Dataset):\n",
        "    def __init__(self,path):\n",
        "        data = pd.read_csv(path)\n",
        "        X = data.drop(['label'],axis=1)\n",
        "        X = X.values.reshape(-1,1,28,28)\n",
        "        X = torch.FloatTensor(X)\n",
        "        y = data['label']\n",
        "        y = y.values.reshape(-1)\n",
        "        y = torch.LongTensor(y)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        a = self.X[idx]\n",
        "        b = self.y[idx]\n",
        "        return a,b"
      ],
      "metadata": {
        "id": "S6T8hIMGrG-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2. Dataset & Dataloader 사용하여 Custom Dataset 만들기 '''\n",
        "train_dataset = CustomDataset1(train_path)\n",
        "test_dataset = CustomDataset1(test_path)\n",
        "train_loader = DataLoader(dataset = train_dataset,\n",
        "                          batch_size = BATCH_SIZE,\n",
        "                          shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = False)"
      ],
      "metadata": {
        "id": "udwXl-XQcsF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 3. 데이터 확인하기(1) '''\n",
        "for (image, label) in train_loader:\n",
        "    print('image:', image.size(), 'type:', image.type())\n",
        "    print('label:', label.size(), 'type:', label.type())\n",
        "    break\n",
        "    ''' 4. 데이터 확인하기 (2) '''\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
        "    plt.title('Class: ' + str(label[i].item()))"
      ],
      "metadata": {
        "id": "ut7sUQk5dEZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 5. Multi Layer Perceptron (MLP) 모델 설계하기 '''\n",
        "class MLP1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP1, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "deHj4W45d3Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 6. Optimizer, Objective Function 설정하기 '''\n",
        "model = MLP1().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "0cxtrTFcj3J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 7. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))"
      ],
      "metadata": {
        "id": "pNpgrpImkSfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 8. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "02h7BH6fkaO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 9. MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "metadata": {
        "id": "MBLDBjKVkoh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.multi-layer perceptron torch 구현\n",
        "Fashion-MNIST"
      ],
      "metadata": {
        "id": "nTDIINGfGYDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2afEYfuePjNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "EDO6b9RgPksg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 1. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ],
      "metadata": {
        "id": "UDcWfheLPlMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Colab Notebooks/Fashion mnist/fashion-mnist_train.csv'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/Fashion mnist/fashion-mnist_test.csv'"
      ],
      "metadata": {
        "id": "44VYY7DHs21r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset2(Dataset):\n",
        "    def __init__(self,path):\n",
        "        data = pd.read_csv(path)\n",
        "        X = data.drop(['label'],axis=1)\n",
        "        X = X.values.reshape(-1,1,28,28)\n",
        "        X = torch.FloatTensor(X)\n",
        "        y = data['label']\n",
        "        y = y.values.reshape(-1)\n",
        "        y = torch.LongTensor(y)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        a = self.X[idx]\n",
        "        b = self.y[idx]\n",
        "        return a,b"
      ],
      "metadata": {
        "id": "-TClOc1ZVZbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2. Dataset & Dataloader 사용하여 Custom Dataset 만들기 '''\n",
        "train_dataset = CustomDataset2(train_path)\n",
        "test_dataset = CustomDataset2(test_path)\n",
        "train_loader = DataLoader(dataset = train_dataset,\n",
        "                          batch_size = BATCH_SIZE,\n",
        "                          shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = False)"
      ],
      "metadata": {
        "id": "to97WH5TWSdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 3. 데이터 확인하기(1) '''\n",
        "for (image, label) in train_loader:\n",
        "    print('image:', image.size(), 'type:', image.type())\n",
        "    print('label:', label.size(), 'type:', label.type())\n",
        "    break"
      ],
      "metadata": {
        "id": "z4Ocg693HRo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 4. 데이터 확인하기 (2) '''\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
        "    plt.title('Class: ' + str(label[i].item()))"
      ],
      "metadata": {
        "id": "8KFxwtMiHaFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 5. Multi Layer Perceptron (MLP) 모델 설계하기 '''\n",
        "class MLP2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "puejg7DYPq8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 6. Optimizer, Objective Function 설정하기 '''\n",
        "model = MLP2().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "RkFoL_qpPs0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 7. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))"
      ],
      "metadata": {
        "id": "YDOqNLcUPunx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 8. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "iqMrLKD-PwVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 9. MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "metadata": {
        "id": "saZGrAdDIBrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.multi-layer perceptron torch 구현\n",
        "CIFAR_10"
      ],
      "metadata": {
        "id": "REgdAb_qIkwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BEzbCKV4P66v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "KTx24AZvP8z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 1. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
      ],
      "metadata": {
        "id": "A2UzKYdQP-kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/cifar-10/cifar-10_train.csv\"\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/cifar-10/cifar-10_test.csv'"
      ],
      "metadata": {
        "id": "cGdknlkZjHUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset3(Dataset):\n",
        "    def __init__(self,path):\n",
        "        data = pd.read_csv(path)\n",
        "        X = data.drop(['label'],axis=1)/255\n",
        "        X = X.values.reshape(-1,3,32,32)\n",
        "        X = torch.FloatTensor(X)\n",
        "        y = data['label']\n",
        "        y = y.values.reshape(-1)\n",
        "        y = torch.LongTensor(y)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        a = self.X[idx]\n",
        "        b = self.y[idx]\n",
        "        return a,b"
      ],
      "metadata": {
        "id": "KBnImlfDiowf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 2. Dataset & Dataloader 사용하여 Custom Dataset 만들기 '''\n",
        "train_dataset = CustomDataset3(train_path)\n",
        "test_dataset = CustomDataset3(test_path)\n",
        "train_loader = DataLoader(dataset = train_dataset,\n",
        "                          batch_size = BATCH_SIZE,\n",
        "                          shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         shuffle = False)"
      ],
      "metadata": {
        "id": "Wn6qB_d_it1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 3. 데이터 확인하기(1) '''\n",
        "for (image, label) in train_loader:\n",
        "    print('image:', image.size(), 'type:', image.type())\n",
        "    print('label:', label.size(), 'type:', label.type())\n",
        "    break"
      ],
      "metadata": {
        "id": "Wwk4qA-RJ5tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 4. 데이터 확인하기 (2) '''\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(image[i], (1, 2, 0)))\n",
        "    plt.title('Class: ' + str(label[i].item()))"
      ],
      "metadata": {
        "id": "nREwIJE3J--9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 5. Multi Layer Perceptron (MLP) 모델 설계하기 '''\n",
        "class MLP3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP3, self).__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 2048)\n",
        "        self.fc2 = nn.Linear(2048,1024)\n",
        "        self.fc3 = nn.Linear(1024,512)\n",
        "        self.fc4 = nn.Linear(512, 256)\n",
        "        self.fc5 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32 * 32 * 3)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kblHwrioLgwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 6. Optimizer, Objective Function 설정하기 '''\n",
        "model = MLP3().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "KAvXZTMlMn2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 7. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))"
      ],
      "metadata": {
        "id": "s3-8J_lFNAsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 8. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "gk8qVW5lNDVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 9. MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "metadata": {
        "id": "C0Ge_ECXNFY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}